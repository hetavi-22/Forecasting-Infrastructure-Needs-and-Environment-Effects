{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, Input\n",
    "\n",
    "def build_modified_vgg16(input_shape=(224, 224, 3), num_classes=4):\n",
    "    def sep_conv_block(x, filters):\n",
    "        x = layers.SeparableConv2D(filters, 3, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        return x\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = sep_conv_block(inputs, 64)\n",
    "    x = sep_conv_block(x, 64)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "\n",
    "    x = sep_conv_block(x, 128)\n",
    "    x = sep_conv_block(x, 128)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "\n",
    "    x = sep_conv_block(x, 256)\n",
    "    res1 = sep_conv_block(x, 256)\n",
    "    x = layers.add([x, res1])\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "\n",
    "    x = sep_conv_block(x, 512)\n",
    "    res2 = sep_conv_block(x, 512)\n",
    "    x = layers.add([x, res2])\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "\n",
    "    x = sep_conv_block(x, 512)\n",
    "    res3 = sep_conv_block(x, 512)\n",
    "    x = layers.add([x, res3])\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs, x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_dataset(image_dir, label_csv, class_map, batch_size=8):\n",
    "    df = pd.read_csv(label_csv)\n",
    "    df['label'] = df['zone_class'].map(class_map)\n",
    "\n",
    "    def process(file, label):\n",
    "        image = tf.io.read_file(file)\n",
    "        image = tf.image.decode_image(image, channels=3)\n",
    "        image = tf.image.resize(image, [224, 224]) / 255.0\n",
    "        return image, label\n",
    "\n",
    "    image_paths = [os.path.join(image_dir, f) for f in df['image_id']]\n",
    "    labels = df['label'].values\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    ds = ds.map(process).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class_map = {\n",
    "    'urban_growth_zone': 0,\n",
    "    'green_recovery_zone': 1,\n",
    "    'stable_zone': 2,\n",
    "    'construction_zone': 3\n",
    "}\n",
    "reverse_map = {v: k for k, v in class_map.items()}\n",
    "\n",
    "train_ds = load_dataset(\"Files/Data/split/train/images\", \"results/yolov8_counts_and_class.csv\", class_map)\n",
    "val_ds = load_dataset(\"Files/Data/split/val/images\", \"results/yolov8_counts_and_class.csv\", class_map)\n",
    "test_ds = load_dataset(\"Files/Data/split/test/images\", \"results/yolov8_counts_and_class.csv\", class_map)\n",
    "\n",
    "model = build_modified_vgg16()\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=10)\n",
    "\n",
    "# Predict on test set\n",
    "preds = model.predict(test_ds)\n",
    "pred_labels = preds.argmax(axis=1)\n",
    "\n",
    "# Save predictions\n",
    "test_filenames = pd.read_csv(\"yolov8_counts_and_class.csv\")['image_id'].tail(len(pred_labels))\n",
    "df = pd.DataFrame({'image_id': test_filenames, 'vgg16_zone_class': [reverse_map[p] for p in pred_labels]})\n",
    "df.to_csv(\"vgg16_predictions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "df = pd.read_csv(\"yolov8_counts_and_class.csv\")\n",
    "forecasts = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    for year in range(2025, 2031):\n",
    "        forecasts.append({\n",
    "            \"image_id\": row[\"image_id\"],\n",
    "            \"year\": year,\n",
    "            \"buildings\": int(row[\"buildings\"]) + random.randint(0, 5),\n",
    "            \"roads\": int(row[\"roads\"]) + random.randint(0, 3),\n",
    "            \"construction_zones\": int(row[\"construction_zones\"]) + random.randint(0, 2)\n",
    "        })\n",
    "\n",
    "forecast_df = pd.DataFrame(forecasts)\n",
    "forecast_df.to_csv(\"gnn_forecast_2025_2030.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
